{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patlollalak/Laxma_projects/blob/master/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8po-oTzUTukf",
        "colab_type": "text"
      },
      "source": [
        "# **Image preprocessing**\n",
        "**Image processing** is divided into analogue image processing and digital image processing.\n",
        "\n",
        "**Digital image processing** is the use of computer algorithms to perform image processing on digital images. It allows a much wider range of algorithms to be applied to the input data - the aim of digital image processing is to improve the image data (features) by suppressing unwanted distortions and/or enhancement of some important image features so that our **AI models** can benefit from this improved data to work on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcL2ZCWyDF2U",
        "colab_type": "text"
      },
      "source": [
        "# **Installing necessary dependencies**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieiTHw1HDwRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OpenCV\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jQf-JqMCRgn",
        "colab_type": "text"
      },
      "source": [
        "# **Python Code using Opencv and matplotlib libraries **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEZu6Q22Bi0e",
        "colab_type": "code",
        "outputId": "a63c01d5-f325-450d-a752-82d6bb89ac6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLPUqjHfKIIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "8cbf2707-7740-4a2a-e1a2-26dad69f53d8"
      },
      "source": [
        "# defining global variable path\n",
        "# Location of my dataset on My Google Drive\n",
        "image_path = \"drive/My Drive/BiSeNet/dataset\"\n",
        "import tensorflow as tf\n",
        "\n",
        "def loadImages(path):\n",
        "    '''Put files into lists and return them as one list with all images \n",
        "     in the folder'''\n",
        "    image_files = sorted([os.path.join(path, 'train', file)\n",
        "                          for file in os.listdir(path + \"/train\")\n",
        "                          if file.endswith('.png')])\n",
        "    return image_files\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jRARxh6RmXp",
        "colab_type": "text"
      },
      "source": [
        "# **Displaying Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MogmXqbeRhsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display two images\n",
        "def display(a, b, title1 = \"Original\", title2 = \"Edited\"):\n",
        "    plt.subplot(121), plt.imshow(a), plt.title(title1)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(122), plt.imshow(b), plt.title(title2)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "# Display one image\n",
        "def display_one(a, title1 = \"Original\"):\n",
        "    plt.imshow(a), plt.title(title1)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD3e08HvWsF3",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing the images:\n",
        "* Read image\n",
        "* Resize image \n",
        "* Remove noise(Denoise)\n",
        "* Segmentation\n",
        "* Morphology(smoothing edges)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEFZjImBRsX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing\n",
        "def processing(data):\n",
        "    \n",
        "    # Reading 3 images to work\n",
        "    img = [cv2.imread(i, cv2.IMREAD_UNCHANGED) for i in data[:3]]\n",
        "    try:\n",
        "        print('Original size',img[0].shape)\n",
        "    except AttributeError:\n",
        "        print(\"shape not found\")\n",
        "   \n",
        "    # --------------------------------\n",
        "    # setting dim of the resize\n",
        "    height = 220\n",
        "    width = 220\n",
        "    dim = (width, height)\n",
        "    res_img = []\n",
        "    for i in range(len(img)):\n",
        "        res = cv2.resize(img[i], dim, interpolation=cv2.INTER_LINEAR)\n",
        "        res_img.append(res)\n",
        "\n",
        "    # Checcking the size\n",
        "    try:\n",
        "        print('RESIZED', res_img[1].shape)\n",
        "    except AttributeError:\n",
        "        print(\"shape not found\")\n",
        "    \n",
        "    \n",
        "    # Visualizing one of the images in the array\n",
        "    original = res_img[1]\n",
        "    display_one(original)\n",
        "    # ----------------------------------\n",
        "    # Remove noise\n",
        "    # Using Gaussian Blur\n",
        "    no_noise = []\n",
        "    for i in range(len(res_img)):\n",
        "        blur = cv2.GaussianBlur(res_img[i], (5, 5), 0)\n",
        "        no_noise.append(blur)\n",
        "\n",
        "\n",
        "    image = no_noise[1]\n",
        "    display(original, image, 'Original', 'Blured')\n",
        "    #---------------------------------\n",
        "    # Segmentation\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Displaying segmented images\n",
        "    display(original, thresh, 'Original', 'Segmented')\n",
        "    # Further noise removal (Morphology)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "\n",
        "    # sure background area\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Finding sure foreground area\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Finding unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    #Displaying segmented back ground\n",
        "    display(original, sure_bg, 'Original', 'Segmented Background')\n",
        "\n",
        "    # Marker labelling\n",
        "    ret, markers = cv2.connectedComponents(sure_fg)\n",
        "\n",
        "    # Add one to all labels so that sure background is not 0, but 1\n",
        "    markers = markers + 1\n",
        "\n",
        "    # Now, mark the region of unknown with zero\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    markers = cv2.watershed(image, markers)\n",
        "    image[markers == -1] = [255, 0, 0]\n",
        "\n",
        "    # Displaying markers on the image\n",
        "    display(original, markers, 'Original', 'Marked')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98rA-U8pXS0g",
        "colab_type": "text"
      },
      "source": [
        "# Main Function the heart of the program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E94MjxkR_hI",
        "colab_type": "code",
        "outputId": "e6f1d821-c595-47c8-9130-ead7d44ef0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "def main():\n",
        "    # calling global variable\n",
        "    global image_path\n",
        "    '''The var Dataset is a list with all images in the folder '''\n",
        "    dataset = loadImages(image_path)\n",
        "    print('number of FILES in dir', len(dataset))\n",
        "    print(\"--------------------------------\")\n",
        "    #print(cv2.imread(dataset[0]).shape)\n",
        "    print(\"List of files the first 3 in the folder:\\n\",dataset[:3])\n",
        "    print(\"--------------------------------\")\n",
        "    \n",
        "    # sending all the images to pre-processing\n",
        "    processing(dataset)\n",
        "   \n",
        "    #list files in directory\n",
        "    #a = tf.gfile.ListDirectory('drive/My Drive/BiSeNet/dataset/train')\n",
        "    #print(a)\n",
        "  \n",
        "main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c09a8b76fe19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-c09a8b76fe19>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'''The var Dataset is a list with all images in the folder '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of FILES in dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-7b1073febc12>\u001b[0m in \u001b[0;36mloadImages\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m      in the folder'''\n\u001b[1;32m      7\u001b[0m     image_files = sorted([os.path.join(path, 'train', file)\n\u001b[0;32m----> 8\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                           if file.endswith('.png')])\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/BiSeNet/dataset/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9UMwEOtShTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}